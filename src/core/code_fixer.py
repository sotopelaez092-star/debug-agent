"""CodeFixer - ä»£ç ä¿®å¤å™¨ï¼ˆæ–°æ¶æ„ï¼‰"""
import json
import re
import logging
from typing import Optional, Dict, Any, List
from openai import AsyncOpenAI

from src.models.results import FixResult
from src.utils.config import get_settings
from src.core.pattern_fixer import PatternFixer
from src.core.llm_cache import LLMCache
from src.core.llm_error_handler import (
    call_llm_with_retry,
    LLMError,
    LLMAuthError,
    LLMRateLimitError,
    LLMTimeoutError
)

logger = logging.getLogger(__name__)


class CodeFixer:
    """ä½¿ç”¨ LLM ç”Ÿæˆä»£ç ä¿®å¤"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "deepseek-chat",
        temperature: float = 0.3,
        max_tokens: int = 2000
    ):
        """
        åˆå§‹åŒ– CodeFixer

        Args:
            api_key: API å¯†é’¥
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼Œè¶Šä½è¶Šç¡®å®šï¼‰
            max_tokens: æœ€å¤§ token æ•°
        """
        settings = get_settings()

        self.api_key = api_key or settings.deepseek_api_key
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=settings.deepseek_base_url or "https://api.deepseek.com/v1"
        )

        # æ¨¡å¼åŒ¹é…å¿«é€Ÿä¿®å¤å™¨
        self.pattern_fixer = PatternFixer()

        # LLM å“åº”ç¼“å­˜
        self.cache = LLMCache()

        # Token ä½¿ç”¨ç»Ÿè®¡
        self.token_stats = {
            "total_prompt_tokens": 0,
            "total_completion_tokens": 0,
            "total_tokens": 0,
            "llm_calls": 0,
            "cache_hits": 0,
            "pattern_hits": 0,
            "tokens_saved_by_cache": 0  # ä¼°ç®—ï¼šæ¯æ¬¡ç¼“å­˜å‘½ä¸­çœçº¦ 2500 tokens
        }

        logger.info(f"CodeFixer åˆå§‹åŒ–: model={self.model}, ç¼“å­˜æ¡ç›®: {len(self.cache._cache)}")

    async def fix_code(
        self,
        buggy_code: str,
        error_message: str,
        context: Optional[Dict[str, Any]] = None,
        rag_solutions: Optional[List[Dict]] = None,
        error_type: Optional[str] = None,
        force_llm: bool = False
    ) -> FixResult:
        """
        ç”Ÿæˆä»£ç ä¿®å¤

        Args:
            buggy_code: åŒ…å«é”™è¯¯çš„ä»£ç 
            error_message: é”™è¯¯æ¶ˆæ¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ¥è‡ª InvestigationReportï¼‰
            rag_solutions: RAG æ£€ç´¢çš„è§£å†³æ–¹æ¡ˆï¼ˆå¯é€‰ï¼‰
            error_type: é”™è¯¯ç±»å‹ï¼ˆå¦‚ NameError, ImportError ç­‰ï¼‰

        Returns:
            FixResult

        Raises:
            ValueError: è¾“å…¥éªŒè¯å¤±è´¥
            RuntimeError: LLM è°ƒç”¨å¤±è´¥
        """
        # éªŒè¯è¾“å…¥
        if not buggy_code or not isinstance(buggy_code, str):
            raise ValueError("buggy_code å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")
        if not error_message or not isinstance(error_message, str):
            raise ValueError("error_message å¿…é¡»æ˜¯éç©ºå­—ç¬¦ä¸²")

        # å°è¯•ä»å‚æ•°æˆ–æ¶ˆæ¯ä¸­è·å–é”™è¯¯ç±»å‹
        if not error_type:
            error_type = self._extract_error_type(error_message)

        # åªæœ‰åœ¨ä¸å¼ºåˆ¶ä½¿ç”¨ LLM æ—¶æ‰å°è¯• PatternFixer
        if error_type and not force_llm:
            pattern_result = self.pattern_fixer.try_fix(buggy_code, error_type, error_message)
            if pattern_result:
                fixed_code, explanation = pattern_result
                logger.info(f"âš¡ æ¨¡å¼åŒ¹é…å¿«é€Ÿä¿®å¤: {explanation}")
                self.token_stats["pattern_hits"] += 1
                self.token_stats["tokens_saved_by_cache"] += 2500  # ä¼°ç®—çœçš„ tokens
                return FixResult(
                    success=True,
                    fixed_code=fixed_code,
                    explanation=f"[å¿«é€Ÿä¿®å¤] {explanation}",
                    changes=[explanation],
                    used_pattern_fixer=True  # æ ‡è®°ä½¿ç”¨äº† PatternFixer
                )
        elif force_llm:
            logger.info("ğŸ”§ å¼ºåˆ¶ä½¿ç”¨ LLMï¼ˆPatternFixer ä¸Šæ¬¡å¤±è´¥ï¼‰")

        # ç¼“å­˜å‘½ä¸­æš‚æ—¶ç¦ç”¨ - ç¼“å­˜åªå­˜ç­–ç•¥æè¿°ï¼Œæ— æ³•ç›´æ¥åº”ç”¨
        # TODO: æ”¹è¿›ç¼“å­˜è®¾è®¡ï¼Œå­˜å‚¨å¯åº”ç”¨çš„ä¿®å¤æ¨¡æ¿
        # if error_type:
        #     cache_entry = self.cache.get(error_type, error_message, buggy_code[:200])
        #     if cache_entry:
        #         logger.info(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­: {error_type} (ç½®ä¿¡åº¦: {cache_entry.confidence:.0%})")
        #         ...

        # æ„å»ºæç¤º
        prompt = self._build_prompt(buggy_code, error_message, context, rag_solutions)

        try:
            # è°ƒç”¨ LLMï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            response = await call_llm_with_retry(
                client=self.client,
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸“ä¸šçš„ Python ä»£ç ä¿®å¤ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æé”™è¯¯å¹¶ç”Ÿæˆä¿®å¤åçš„ä»£ç ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                max_retries=3,
                timeout=60.0
            )

            # è®°å½• token ä½¿ç”¨
            if hasattr(response, 'usage') and response.usage:
                self.token_stats["total_prompt_tokens"] += response.usage.prompt_tokens
                self.token_stats["total_completion_tokens"] += response.usage.completion_tokens
                self.token_stats["total_tokens"] += response.usage.total_tokens
                self.token_stats["llm_calls"] += 1
                logger.info(f"ğŸ“Š Token ä½¿ç”¨: {response.usage.total_tokens} (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})")

            # è§£æå“åº”
            content = response.choices[0].message.content
            result = self._parse_response(content, buggy_code)

            # å­˜å…¥ç¼“å­˜
            if error_type and result.fixed_code != buggy_code:
                self.cache.put(
                    error_type=error_type,
                    error_message=error_message,
                    fix_strategy=result.explanation[:200] if result.explanation else "",
                    fixed_code=result.fixed_code[:500],  # åªå­˜å‚¨éƒ¨åˆ†ä»£ç ä½œä¸ºæ¨¡æ¿
                    explanation=result.explanation or "",
                    code_context=buggy_code[:200]
                )

            return result

        except LLMAuthError as e:
            logger.error(f"API è®¤è¯å¤±è´¥: {e}")
            raise RuntimeError(f"API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key: {e}")

        except LLMRateLimitError as e:
            logger.error(f"API é€Ÿç‡é™åˆ¶: {e}")
            raise RuntimeError(f"API é€Ÿç‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•: {e}")

        except LLMTimeoutError as e:
            logger.error(f"è¯·æ±‚è¶…æ—¶: {e}")
            raise RuntimeError(f"LLM è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥: {e}")

        except LLMError as e:
            logger.error(f"LLM è°ƒç”¨å¤±è´¥: {e}", exc_info=True)
            raise RuntimeError(f"ä»£ç ä¿®å¤å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {e}", exc_info=True)
            raise RuntimeError(f"ä»£ç ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

    def _build_prompt(
        self,
        buggy_code: str,
        error_message: str,
        context: Optional[Dict[str, Any]],
        rag_solutions: Optional[List[Dict]]
    ) -> str:
        """æ„å»ºä¿®å¤æç¤º"""
        sections = []

        # 1. é”™è¯¯ä»£ç 
        sections.append("## é”™è¯¯ä»£ç ")
        sections.append("```python")
        sections.append(buggy_code)
        sections.append("```")

        # 2. é”™è¯¯ä¿¡æ¯
        sections.append("\n## é”™è¯¯ä¿¡æ¯")
        sections.append(f"```\n{error_message}\n```")

        # 3. ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if context:
            sections.append("\n## ä¸Šä¸‹æ–‡ä¿¡æ¯")

            if "investigation_summary" in context:
                sections.append(f"**è°ƒæŸ¥æ€»ç»“**: {context['investigation_summary']}")

            if "root_cause" in context:
                sections.append(f"**æ ¹æœ¬åŸå› **: {context['root_cause']}")

            if "suggested_fix" in context:
                sections.append(f"**å»ºè®®ä¿®å¤**: {context['suggested_fix']}")

            if "relevant_locations" in context:
                sections.append("\n**ç›¸å…³ä½ç½®**:")
                for loc in context["relevant_locations"]:
                    sections.append(f"- {loc.get('file')}:{loc.get('line')} - {loc.get('symbol')}")
                    sections.append(f"  åŸå› : {loc.get('reasoning')}")

            if "related_symbols" in context:
                sections.append("\n**ç›¸å…³ç¬¦å·å®šä¹‰**:")
                for symbol, info in context["related_symbols"].items():
                    sections.append(f"- `{symbol}` ({info.get('type')}) åœ¨ {info.get('file')}:{info.get('line')}")
                    if info.get("definition"):
                        sections.append(f"  ```python\n  {info['definition']}\n  ```")

            # ç­–ç•¥ä¸Šä¸‹æ–‡ï¼ˆç”¨äº CircularImport å’Œ KeyErrorï¼‰
            if "strategy_context" in context:
                sc = context["strategy_context"]
                sections.append("\n**ã€é‡è¦ã€‘å…·ä½“ä¿®å¤æŒ‡å—**:")

                # CircularImport ç­–ç•¥
                if sc.get("circular_import"):
                    sections.append(f"- è¿™æ˜¯å¾ªç¯å¯¼å…¥é—®é¢˜")
                    sections.append(f"- æ¶‰åŠç¬¦å·: `{sc.get('symbol')}`")
                    sections.append(f"- æ¶‰åŠæ¨¡å—: `{sc.get('module')}`")
                    sections.append(f"- æ¨èç­–ç•¥: **{sc.get('fix_strategy', 'TYPE_CHECKING')}**")
                    if sc.get("fix_instructions"):
                        sections.append("- ä¿®å¤æ­¥éª¤:")
                        for instr in sc.get("fix_instructions", []):
                            sections.append(f"  {instr}")
                    if sc.get("fix_code_template"):
                        sections.append("- å‚è€ƒä»£ç æ¨¡æ¿:")
                        sections.append(f"```python\n{sc.get('fix_code_template')}\n```")

                # KeyError åµŒå¥—ç»“æ„ç­–ç•¥
                if sc.get("fix_type") in ["nested", "restructured"]:
                    sections.append(f"- è¿™æ˜¯å­—å…¸é”®è®¿é—®é—®é¢˜")
                    sections.append(f"- ç¼ºå¤±çš„é”®: `{sc.get('missing_key')}`")
                    sections.append(f"- è®¿é—®è·¯å¾„å·²å˜æ›´ä¸ºåµŒå¥—ç»“æ„")
                    sections.append(f"- **æ­£ç¡®è®¿é—®æ–¹å¼**: `{sc.get('fix_code', '')}`")
                    sections.append(f"- **åŸé”™è¯¯ä»£ç **: `{sc.get('original_code', '')}`")
                    sections.append(f"- æ¥æº: {sc.get('source_file')} çš„ {sc.get('source_function')}() å‡½æ•°")

        # 4. RAG è§£å†³æ–¹æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
        if rag_solutions:
            sections.append("\n## å‚è€ƒè§£å†³æ–¹æ¡ˆï¼ˆStack Overflowï¼‰")
            for i, sol in enumerate(rag_solutions[:3], 1):  # æœ€å¤šæ˜¾ç¤º 3 ä¸ª
                sections.append(f"\n### æ–¹æ¡ˆ {i}")
                sections.append(sol.get("content", "")[:500])  # é™åˆ¶é•¿åº¦

        # 5. ä»»åŠ¡è¯´æ˜
        sections.append("\n## ä»»åŠ¡")
        sections.append("è¯·ä¿®å¤ä¸Šè¿°ä»£ç ä¸­çš„é”™è¯¯ï¼Œå¹¶è¿”å› JSON æ ¼å¼çš„å“åº”ã€‚")
        sections.append("\n**è¦æ±‚**:")
        sections.append("1. ä»”ç»†åˆ†æé”™è¯¯åŸå› ")
        sections.append("2. **æ£€æŸ¥æ•´ä¸ªä»£ç æ–‡ä»¶ï¼Œæ‰¾å‡ºå¹¶ä¿®å¤æ‰€æœ‰ç±»ä¼¼çš„é”™è¯¯**ï¼ˆä¾‹å¦‚ï¼šå¦‚æœæœ‰ä¸€ä¸ªæ–¹æ³•åæ‹¼å†™é”™è¯¯ï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–ç±»ä¼¼çš„æ‹¼å†™é”™è¯¯ï¼‰")
        sections.append("3. ç”Ÿæˆä¿®å¤åçš„**å®Œæ•´ä»£ç **ï¼ˆä¸è¦çœç•¥ä»»ä½•éƒ¨åˆ†ï¼‰")
        sections.append("4. ç¡®ä¿ä¿®å¤åçš„ä»£ç å¯ä»¥æ­£å¸¸è¿è¡Œ")
        sections.append("5. ä¿æŒåŸæœ‰çš„ä»£ç ç»“æ„å’Œé€»è¾‘")
        sections.append("6. **é‡è¦ï¼šä¸è¦ä¿®æ”¹å‡½æ•°åã€ç±»åã€æ–¹æ³•åç­‰å…¬å…± API å®šä¹‰**ï¼ˆå…¶ä»–æ–‡ä»¶å¯èƒ½ä¾èµ–è¿™äº›åç§°ï¼‰ã€‚åªä¿®å¤å‡½æ•°å†…éƒ¨çš„é”™è¯¯ï¼ˆå¦‚ `rnage` â†’ `range`ï¼‰ï¼Œä¸è¦æŠŠå‡½æ•°åå¦‚ `create_matrx` æ”¹æˆ `create_matrix`")

        # ç‰¹æ®Šé”™è¯¯ç±»å‹çš„å¤„ç†æŒ‡å—
        sections.append("\n## ç‰¹æ®Šé”™è¯¯å¤„ç†æŒ‡å—")
        sections.append("""
**å¾ªç¯å¯¼å…¥ (CircularImport/partially initialized module)**:
å¦‚æœé”™è¯¯æ˜¯å¾ªç¯å¯¼å…¥ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ¡ˆä¹‹ä¸€ï¼š
1. **TYPE_CHECKING æ–¹æ¡ˆ**ï¼ˆæ¨èç”¨äºç±»å‹æ³¨è§£ï¼‰:
   ```python
   from typing import TYPE_CHECKING
   if TYPE_CHECKING:
       from module import Class  # åªåœ¨ç±»å‹æ£€æŸ¥æ—¶å¯¼å…¥

   def func(param: "Class"):  # ä½¿ç”¨å­—ç¬¦ä¸²æ³¨è§£
       ...
   ```
2. **å»¶è¿Ÿå¯¼å…¥æ–¹æ¡ˆ**ï¼ˆç”¨äºè¿è¡Œæ—¶éœ€è¦çš„å¯¼å…¥ï¼‰:
   ```python
   def create_something():
       from module import Class  # ç§»åˆ°å‡½æ•°å†…éƒ¨
       return Class()
   ```
3. **ç§»é™¤ä¸å¿…è¦çš„å¯¼å…¥**ï¼šå¦‚æœå¯¼å…¥åªç”¨äºç±»å‹æ³¨è§£ä¸”å¯ä»¥çœç•¥ï¼Œç›´æ¥åˆ é™¤ã€‚

**KeyError åµŒå¥—å­—å…¸**:
å¦‚æœé”™è¯¯æ˜¯ KeyError ä¸”ä¸Šä¸‹æ–‡æåˆ°"åµŒå¥—ç»“æ„"æˆ–"é‡æ„"ï¼š
- æ£€æŸ¥å­—å…¸çš„å®é™…ç»“æ„ï¼ˆä»ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸­æŸ¥çœ‹ï¼‰
- å°† `dict["old_key"]` æ”¹ä¸º `dict["parent"]["child"]`
- ä¾‹å¦‚: `config["log_level"]` â†’ `config["logging"]["level"]`
""")

        sections.append("\n**è¿”å›æ ¼å¼** (ä¸¥æ ¼çš„ JSON):")
        sections.append("```json")
        sections.append("{")
        sections.append('  "fixed_code": "ä¿®å¤åçš„å®Œæ•´ä»£ç ",')
        sections.append('  "explanation": "ä¿®å¤è¯´æ˜ï¼ˆç®€æ´æ˜äº†ï¼‰",')
        sections.append('  "changes": ["å…·ä½“æ”¹åŠ¨1", "å…·ä½“æ”¹åŠ¨2"]')
        sections.append("}")
        sections.append("```")

        return "\n".join(sections)

    def _parse_response(self, content: str, original_code: str) -> FixResult:
        """è§£æ LLM å“åº”"""
        try:
            # 1. å°è¯•æå– JSON ä»£ç å—
            json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                data = json.loads(json_str)
            else:
                # 2. å°è¯•ç›´æ¥è§£æ JSON
                # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                start = content.find('{')
                end = content.rfind('}')
                if start != -1 and end != -1:
                    json_str = content[start:end+1]
                    data = json.loads(json_str)
                else:
                    raise ValueError("æœªæ‰¾åˆ° JSON å†…å®¹")

            # æå–å­—æ®µ
            fixed_code = data.get("fixed_code", "")
            explanation = data.get("explanation", "")
            changes = data.get("changes", [])

            if not fixed_code:
                raise ValueError("fixed_code ä¸ºç©º")

            logger.info("æˆåŠŸè§£æ LLM å“åº”")
            return FixResult(
                success=True,
                fixed_code=fixed_code,
                explanation=explanation,
                changes=changes if isinstance(changes, list) else []
            )

        except Exception as e:
            logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ")
            # å›é€€ï¼šæå–ä»£ç å—
            code_match = re.search(r'```python\s*\n(.*?)\n```', content, re.DOTALL)
            if code_match:
                fixed_code = code_match.group(1)
            else:
                # æœ€åçš„å›é€€ï¼šä½¿ç”¨åŸå§‹ä»£ç 
                logger.error("æ— æ³•æå–ä¿®å¤ä»£ç ï¼Œè¿”å›åŸå§‹ä»£ç ")
                fixed_code = original_code

            return FixResult(
                success=True,
                fixed_code=fixed_code,
                explanation=f"LLM å“åº”è§£æå¤±è´¥ï¼Œæå–çš„ä»£ç å¯èƒ½ä¸å®Œæ•´",
                changes=[]
            )

    def _extract_error_type(self, error_message: str) -> Optional[str]:
        """ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–é”™è¯¯ç±»å‹"""
        error_types = [
            "NameError", "AttributeError", "TypeError", "ImportError",
            "ModuleNotFoundError", "KeyError", "IndexError", "ValueError",
            "ZeroDivisionError", "FileNotFoundError", "SyntaxError"
        ]
        for err_type in error_types:
            if err_type in error_message:
                return err_type
        return None

    def get_token_stats(self) -> Dict[str, Any]:
        """è·å– token ä½¿ç”¨ç»Ÿè®¡"""
        stats = self.token_stats.copy()
        # è®¡ç®—èŠ‚çœæ¯”ä¾‹
        if stats["total_tokens"] > 0:
            total_would_use = stats["total_tokens"] + stats["tokens_saved_by_cache"]
            stats["savings_percent"] = (stats["tokens_saved_by_cache"] / total_would_use * 100) if total_would_use > 0 else 0
        else:
            stats["savings_percent"] = 0
        return stats

    def save_token_stats(self):
        """ä¿å­˜ token ç»Ÿè®¡åˆ°æ–‡ä»¶"""
        from pathlib import Path
        stats_file = Path(".debug_agent_cache/token_stats.json")
        stats_file.parent.mkdir(exist_ok=True)

        # è¯»å–ç°æœ‰ç»Ÿè®¡å¹¶ç´¯åŠ 
        existing = {}
        if stats_file.exists():
            try:
                existing = json.loads(stats_file.read_text(encoding='utf-8'))
            except:
                pass

        # ç´¯åŠ ç»Ÿè®¡
        for key in ["total_prompt_tokens", "total_completion_tokens", "total_tokens",
                    "llm_calls", "cache_hits", "pattern_hits", "tokens_saved_by_cache"]:
            existing[key] = existing.get(key, 0) + self.token_stats[key]

        stats_file.write_text(json.dumps(existing, indent=2), encoding='utf-8')
        logger.info(f"Token ç»Ÿè®¡å·²ä¿å­˜: {existing}")
