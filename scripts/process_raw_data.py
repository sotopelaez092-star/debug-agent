# scripts/process_raw_data.py
"""
æ•°æ®å¤„ç†ï¼šæ•´åˆæ‰€æœ‰æ•°æ®æºï¼Œç»Ÿä¸€æ ¼å¼
è¾“å‡ºï¼šdata/processed/bugs_raw.json
"""

import json
from pathlib import Path
from typing import List, Dict

def process_base_errors() -> List[Dict]:
    """
    å¤„ç†åŸºç¡€é”™è¯¯æ•°æ®é›†
    ä» data/raw/python_errors_base.json è¯»å–å¹¶æ ‡å‡†åŒ–
    """

    with open('data/processed/python_errors_base.json','r') as f:
        data = json.load(f)

    processed = []
    for error in data["errors"]:
        processed.append({
            'id': f"base_{error['id']}",
            'category': error['category'],
            'difficulty': error['difficulty'],
            'error_type': error.get('error_type', ''),
            'buggy_code': error['buggy_code'],
            'error_message': error['error_message'],
            'fixed_code': error['fixed_code'],
            'explanation': error['explanation'],
            'solution_steps': error['solution_steps'],
            'source': 'manual',
            'verified': True
        })
        
    return processed

def process_bugsinpy_data() -> List[Dict]:
    """
    å¤„ç†BugsInPyæ•°æ®
    ä» bugsinpy_sample.json è¯»å–å¹¶æ ‡å‡†åŒ–
    """
    with open('data/processed/bugsinpy_sample.json','r') as f:
        data = json.load(f)

    processed = []
    for bug in data["bugs"]:
        processed.append({
            'id': bug['id'],
            'category': 'Real Bug',
            'difficulty': bug['difficulty'],
            'error_type': '',
            'buggy_code': '',
            'error_message': '',
            'fixed_code': '',
            'explanation': bug.get('description', ''),
            'solution_steps': [],
            'source': 'bugsinpy',
            'project': bug['project'],
            'bug_id': bug['bug_id'],
            'verified': False
        })
        
    return processed

def merge_and_clean(base_data: List[Dict], bugsinpy_data: List[Dict]) -> List[Dict]:
    """
    åˆå¹¶å¹¶æ¸…æ´—æ•°æ®

    æ¸…æ´—è§„åˆ™ï¼š
    1. å»é™¤é‡å¤
    2. éªŒè¯å¿…å¡«å­—æ®µ
    3. ç»Ÿä¸€æ ¼å¼
    """
    all_data = base_data + bugsinpy_data
    
    # å»é‡
    seen = set()
    cleaned = []

    for item in all_data:
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†
        category = item.get("category", "Unknown")
        buggy_code = item.get("buggy_code", "")
        unique_key = f"{item.get('id', '')}_{category}_{buggy_code}"

        if unique_key not in seen:
            seen.add(unique_key)
            cleaned.append(item)

    print(f'åŸå§‹æ•°æ®ï¼š{len(all_data)}')
    print(f"å»é‡åï¼š{len(cleaned)}")

    return cleaned

def categorize_errors(data: List[Dict]) -> Dict[str, List[Dict]]:
    """
    æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»
    """
    categories ={}

    for item in data:
        category = item['category']
        if category not in categories:
            categories[category] = []
        categories[category].append(item)
    return categories


def annotate_data(data: List[Dict]) -> List[Dict]:
    """
    æ•°æ®æ ‡æ³¨ï¼šæ·»åŠ é¢å¤–çš„å…ƒæ•°æ®
    """
    for item in data:
        # 1. æ·»åŠ å¤æ‚åº¦è¯„åˆ†ï¼ˆåŸºäºä»£ç é•¿åº¦å’Œé”™è¯¯ç±»å‹ï¼‰
        code_length = len(item['buggy_code'])
        if code_length < 50:
            complexity_score =1
        elif code_length < 100:
            complexity_score =2
        else:
            complexity_score =3
        
        item['complexity_score'] = complexity_score

        # 2. æ·»åŠ æ ‡ç­¾
        tags = []
        if 'None' in item['buggy_code']:
            tags.append('none_check')
        if 'try' in item['buggy_code']:
            tags.append('try_except')
        if 'if' in item['buggy_code']:
            tags.append('if_statement')

        item['tags'] = tags

        # 3. æ·»åŠ æ—¶é—´æˆ³
        from datetime import datetime
        item['processed_at'] = datetime.now().isoformat()

    return data

def main():
    """ä¸»æµç¨‹"""
    print("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®...")

    # 1. è¯»å–åŸºç¡€æ•°æ®
    print("\nğŸ“¥ è¯»å–åŸºç¡€é”™è¯¯æ•°æ®...")
    base_data = process_base_errors()
    print(f"âœ… åŸºç¡€æ•°æ®: {len(base_data)} æ¡")

    # 2. è¯»å–BugsInPyæ•°æ®
    print("\nğŸ“¥ è¯»å–BugsInPyæ•°æ®...")
    bugsinpy_data = process_bugsinpy_data()
    print(f"âœ… BugsInPyæ•°æ®: {len(bugsinpy_data)} æ¡")

    # 3. åˆå¹¶å’Œæ¸…æ´—
    print("\nğŸ§¹ åˆå¹¶å’Œæ¸…æ´—æ•°æ®...")
    cleaned_data = merge_and_clean(base_data, bugsinpy_data)
    print(f"âœ… æ¸…æ´—å: {len(cleaned_data)} æ¡")

    # 4. åˆ†ç±»
    print("\nğŸ“‚ æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»...")
    categorized = categorize_errors(cleaned_data)
    print(f"âœ… é”™è¯¯ç±»å‹: {len(categorized)} ç§")
    for cat, items in categorized.items():
        print(f"  - {cat}: {len(items)} æ¡")
    
    # 5. æ ‡æ³¨
    print("\nğŸ·ï¸  æ•°æ®æ ‡æ³¨...")
    annotated_data = annotate_data(cleaned_data)
    print(f"âœ… æ ‡æ³¨å®Œæˆ")

    # 6. ä¿å­˜
    output = {
        'metadata': {
            'version': '1.0',
            'total_count': len(annotated_data),
            'sources': ['manual', 'bugsinpy'],
            'categories': list(categorized.keys()),
            'processing_date': datetime.now().isoformat()
        },
        'categories': categorized,
        'all_bugs': annotated_data
    }
    
    output_path = Path('data/processed/bugs_raw.json')
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… æ•°æ®å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")
    print(f"ğŸ“Š æ€»è®¡: {len(annotated_data)} æ¡æ•°æ®")

if __name__ == "__main__":
    from datetime import datetime
    main()