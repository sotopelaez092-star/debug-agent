"""
Rerankeræ ¼å¼éªŒè¯æµ‹è¯•

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯rerankerè¾“å…¥æ ¼å¼æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥åˆ†æ•°åˆ†å¸ƒæ˜¯å¦åˆç†
3. å¯¹æ¯”æ’åºå˜åŒ–
4. æ€§èƒ½åˆ†æ

ä½¿ç”¨ï¼šçœŸå®æ•°æ®ï¼Œ40ä¸ªæ–‡æ¡£ï¼Œå®Œæ•´åˆ†æ
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import time
import logging
from typing import List, Dict, Any
import json
import chromadb
from FlagEmbedding import FlagReranker

from src.rag.retriever import BaseRetriever
from src.rag.embedder import Embedder
from src.rag.config import RAGConfig

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é…ç½®
CONFIG = {
    'vectorstore_path': 'data/vectorstore/chroma_s1',
    'embedding_model': 'BAAI/bge-small-en-v1.5',
    'reranker_model': 'BAAI/bge-reranker-base',
    'test_query': "AttributeError: 'NoneType' object has no attribute",
    'recall_k': 40,  # å¬å›40ä¸ª
    'top_k': 5       # æœ€ç»ˆè¿”å›5ä¸ª
}


def load_vectorstore() -> chromadb.Collection:
    """
    åŠ è½½å‘é‡æ•°æ®åº“
    
    Returns:
        ChromaDB collection
        
    Raises:
        FileNotFoundError: å¦‚æœvectorstoreè·¯å¾„ä¸å­˜åœ¨
    """
    vectorstore_path = Path(CONFIG['vectorstore_path'])
    
    if not vectorstore_path.exists():
        raise FileNotFoundError(f"Vectorstoreä¸å­˜åœ¨: {vectorstore_path}")
    
    logger.info(f"ğŸ“‚ åŠ è½½vectorstore: {vectorstore_path}")
    
    client = chromadb.PersistentClient(path=str(vectorstore_path))
    collection = client.get_collection(name="stackoverflow_kb")
    
    logger.info(f"âœ… VectorstoreåŠ è½½æˆåŠŸï¼Œæ–‡æ¡£æ•°ï¼š{collection.count()}")
    
    return collection


def load_models() -> tuple[BaseRetriever, FlagReranker]:
    """
    åŠ è½½æ£€ç´¢å™¨å’ŒReranker
    
    Returns:
        (base_retriever, reranker)
    """
    logger.info("ğŸ¤– åŠ è½½æ¨¡å‹...")
    
    # 1. åŠ è½½å‘é‡æ•°æ®åº“
    collection = load_vectorstore()
    
    # 2. åŠ è½½Embedder
    embedder = Embedder(model_name=CONFIG['embedding_model'])
    logger.info(f"âœ… EmbedderåŠ è½½æˆåŠŸ: {CONFIG['embedding_model']}")
    
    # 3. åˆ›å»ºBaseRetriever
    retriever = BaseRetriever(
        collection=collection,
        embedding_function=embedder,
        min_similarity=0.5,
        recall_factor=4
    )
    logger.info("âœ… BaseRetrieveråˆ›å»ºæˆåŠŸ")
    
    # 4. åŠ è½½Reranker
    reranker = FlagReranker(
        CONFIG['reranker_model'],
        use_fp16=True
    )
    logger.info(f"âœ… RerankeråŠ è½½æˆåŠŸ: {CONFIG['reranker_model']}")
    
    return retriever, reranker


def test_base_retrieval(retriever: BaseRetriever, query: str, top_k: int) -> List[Dict[str, Any]]:
    """
    æµ‹è¯•åŸºç¡€æ£€ç´¢
    
    Args:
        retriever: æ£€ç´¢å™¨
        query: æŸ¥è¯¢æ–‡æœ¬
        top_k: è¿”å›æ•°é‡
        
    Returns:
        æ£€ç´¢ç»“æœåˆ—è¡¨
    """
    logger.info("=" * 80)
    logger.info("ğŸ” Step 1: åŸºç¡€å‘é‡æ£€ç´¢")
    logger.info("=" * 80)
    
    start_time = time.time()
    results = retriever.search(query, top_k=top_k)
    retrieval_time = time.time() - start_time
    
    logger.info(f"â±ï¸  æ£€ç´¢è€—æ—¶: {retrieval_time*1000:.2f}ms")
    logger.info(f"ğŸ“Š å¬å›æ•°é‡: {len(results)}")
    
    if results:
        similarities = [r['similarity'] for r in results]
        logger.info(f"ğŸ“ˆ ç›¸ä¼¼åº¦èŒƒå›´: {min(similarities):.4f} ~ {max(similarities):.4f}")
        logger.info(f"ğŸ“ˆ å¹³å‡ç›¸ä¼¼åº¦: {sum(similarities)/len(similarities):.4f}")
        
        # æ‰“å°Top 5
        logger.info("\nğŸ† Top 5 æ–‡æ¡£ï¼ˆå‘é‡æ£€ç´¢ï¼‰:")
        for i, doc in enumerate(results[:5], 1):
            content_preview = doc['content'][:100].replace('\n', ' ')
            logger.info(
                f"  {i}. [ç›¸ä¼¼åº¦={doc['similarity']:.4f}] "
                f"ID={doc['id'][:20]}... "
                f"å†…å®¹={content_preview}..."
            )
    
    return results


def test_reranker(
    reranker: FlagReranker,
    query: str,
    candidates: List[Dict[str, Any]],
    top_k: int
) -> tuple[List[Dict[str, Any]], float]:
    """
    æµ‹è¯•Reranker
    
    Args:
        reranker: Rerankeræ¨¡å‹
        query: æŸ¥è¯¢æ–‡æœ¬
        candidates: å€™é€‰æ–‡æ¡£
        top_k: è¿”å›æ•°é‡
        
    Returns:
        (reranked_results, rerank_time)
    """
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ¯ Step 2: Rerankeré‡æ’åº")
    logger.info("=" * 80)
    
    if not candidates:
        logger.warning("âš ï¸  æ²¡æœ‰å€™é€‰æ–‡æ¡£")
        return [], 0.0
    
    # 1. æ„é€ è¾“å…¥æ ¼å¼
    logger.info(f"ğŸ“ æ„é€ è¾“å…¥ pairs...")
    logger.info(f"   Queryé•¿åº¦: {len(query)} å­—ç¬¦")
    logger.info(f"   æ–‡æ¡£æ•°é‡: {len(candidates)}")
    
    # æ£€æŸ¥æ–‡æ¡£é•¿åº¦
    doc_lengths = [len(doc['content']) for doc in candidates]
    logger.info(f"   æ–‡æ¡£é•¿åº¦: min={min(doc_lengths)}, max={max(doc_lengths)}, avg={sum(doc_lengths)/len(doc_lengths):.0f}")
    
    pairs = [[query, doc['content']] for doc in candidates]
    
    # æ‰“å°ç¬¬ä¸€ä¸ªpairç¤ºä¾‹
    logger.info(f"\nğŸ“‹ ç¬¬ä¸€ä¸ªpairç¤ºä¾‹:")
    logger.info(f"   Query: {pairs[0][0][:100]}...")
    logger.info(f"   Doc: {pairs[0][1][:200]}...")
    
    # 2. è°ƒç”¨Reranker
    try:
        logger.info(f"\nâš™ï¸  å¼€å§‹Rerankeræ¨ç†...")
        start_time = time.time()
        
        scores = reranker.compute_score(pairs)
        
        rerank_time = time.time() - start_time
        logger.info(f"âœ… Rerankå®Œæˆ!")
        logger.info(f"â±ï¸  è€—æ—¶: {rerank_time:.3f}ç§’ ({rerank_time*1000:.1f}ms)")
        logger.info(f"âš¡ å¹³å‡æ¯ä¸ªæ–‡æ¡£: {rerank_time/len(candidates)*1000:.1f}ms")
        
    except Exception as e:
        logger.error(f"âŒ Rerankå¤±è´¥: {e}", exc_info=True)
        return candidates[:top_k], 0.0
    
    # 3. å¤„ç†åˆ†æ•°
    if not isinstance(scores, list):
        scores = [scores]
    
    logger.info(f"\nğŸ“Š Rerankåˆ†æ•°åˆ†æ:")
    logger.info(f"   åˆ†æ•°ç±»å‹: {type(scores)}")
    logger.info(f"   åˆ†æ•°æ•°é‡: {len(scores)}")
    logger.info(f"   åˆ†æ•°èŒƒå›´: {min(scores):.4f} ~ {max(scores):.4f}")
    logger.info(f"   å¹³å‡åˆ†æ•°: {sum(scores)/len(scores):.4f}")
    
    # 4. æ·»åŠ åˆ†æ•°åˆ°æ–‡æ¡£
    for doc, score in zip(candidates, scores):
        doc['rerank_score'] = float(score)
    
    # 5. é‡æ–°æ’åº
    reranked = sorted(
        candidates,
        key=lambda x: x['rerank_score'],
        reverse=True
    )
    
    # 6. æ‰“å°Top 5
    logger.info("\nğŸ† Top 5 æ–‡æ¡£ï¼ˆRerankerï¼‰:")
    for i, doc in enumerate(reranked[:5], 1):
        content_preview = doc['content'][:100].replace('\n', ' ')
        logger.info(
            f"  {i}. [Rerank={doc['rerank_score']:.4f}, Vector={doc['similarity']:.4f}] "
            f"ID={doc['id'][:20]}... "
            f"å†…å®¹={content_preview}..."
        )
    
    return reranked[:top_k], rerank_time


def compare_results(
    base_results: List[Dict[str, Any]],
    reranked_results: List[Dict[str, Any]],
    top_k: int
) -> None:
    """
    å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„ç»“æœ
    
    Args:
        base_results: åŸºç¡€æ£€ç´¢ç»“æœ
        reranked_results: Rerankåçš„ç»“æœ
        top_k: å¯¹æ¯”å‰Kä¸ª
    """
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“Š Step 3: ç»“æœå¯¹æ¯”åˆ†æ")
    logger.info("=" * 80)
    
    # 1. æå–Top Kçš„ID
    base_ids = [doc['id'] for doc in base_results[:top_k]]
    rerank_ids = [doc['id'] for doc in reranked_results[:top_k]]
    
    # 2. è®¡ç®—å˜åŒ–
    same_count = len(set(base_ids) & set(rerank_ids))
    change_rate = (top_k - same_count) / top_k * 100
    
    logger.info(f"\nğŸ“ˆ æ’åºå˜åŒ–ç»Ÿè®¡ï¼ˆTop {top_k}ï¼‰:")
    logger.info(f"   ç›¸åŒæ–‡æ¡£: {same_count}/{top_k}")
    logger.info(f"   å˜åŒ–ç‡: {change_rate:.1f}%")
    
    # 3. é€ä¸ªå¯¹æ¯”
    logger.info(f"\nğŸ”„ é€ä½å¯¹æ¯”:")
    for i in range(top_k):
        base_doc = base_results[i]
        rerank_doc = reranked_results[i]
        
        if base_doc['id'] == rerank_doc['id']:
            status = "âœ… ç›¸åŒ"
        else:
            status = "ğŸ”„ å˜åŒ–"
        
        logger.info(f"  ä½ç½® {i+1}:")
        logger.info(f"    Vector: {base_doc['id'][:30]}... (ç›¸ä¼¼åº¦={base_doc['similarity']:.4f})")
        logger.info(f"    Rerank: {rerank_doc['id'][:30]}... (åˆ†æ•°={rerank_doc['rerank_score']:.4f}) {status}")
    
    # 4. æ‰¾å‡ºè¢«"é™çº§"çš„é«˜è´¨é‡æ–‡æ¡£
    logger.info(f"\nâš ï¸  æ½œåœ¨é—®é¢˜åˆ†æ:")
    demoted = []
    for i, base_doc in enumerate(base_results[:top_k]):
        # åœ¨rerankç»“æœä¸­çš„ä½ç½®
        try:
            new_rank = [d['id'] for d in reranked_results].index(base_doc['id']) + 1
            if new_rank > i + 1:  # æ’åä¸‹é™
                demoted.append({
                    'id': base_doc['id'][:30],
                    'old_rank': i + 1,
                    'new_rank': new_rank,
                    'similarity': base_doc['similarity'],
                    'rerank_score': base_doc['rerank_score']
                })
        except ValueError:
            # ä¸åœ¨top_kä¸­
            pass
    
    if demoted:
        logger.info(f"   å‘ç° {len(demoted)} ä¸ªé«˜è´¨é‡æ–‡æ¡£è¢«é™çº§:")
        for d in demoted:
            logger.info(
                f"     {d['id']}... "
                f"æ’å {d['old_rank']} â†’ {d['new_rank']} "
                f"(ç›¸ä¼¼åº¦={d['similarity']:.4f}, Rerank={d['rerank_score']:.4f})"
            )
    else:
        logger.info("   âœ… æ²¡æœ‰é«˜è´¨é‡æ–‡æ¡£è¢«æ˜æ˜¾é™çº§")


def save_results(
    query: str,
    base_results: List[Dict[str, Any]],
    reranked_results: List[Dict[str, Any]],
    base_time: float,
    rerank_time: float
) -> None:
    """
    ä¿å­˜æµ‹è¯•ç»“æœ
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        base_results: åŸºç¡€æ£€ç´¢ç»“æœ
        reranked_results: Rerankç»“æœ
        base_time: åŸºç¡€æ£€ç´¢è€—æ—¶
        rerank_time: Rerankè€—æ—¶
    """
    output_path = Path("tests/results/reranker_debug/comparison.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # å‡†å¤‡æ•°æ®
    data = {
        'query': query,
        'base_retrieval': {
            'time_ms': base_time * 1000,
            'results': [
                {
                    'rank': i + 1,
                    'id': doc['id'],
                    'similarity': doc['similarity'],
                    'content_preview': doc['content'][:200]
                }
                for i, doc in enumerate(base_results[:10])
            ]
        },
        'reranked': {
            'time_ms': rerank_time * 1000,
            'results': [
                {
                    'rank': i + 1,
                    'id': doc['id'],
                    'rerank_score': doc['rerank_score'],
                    'similarity': doc['similarity'],
                    'content_preview': doc['content'][:200]
                }
                for i, doc in enumerate(reranked_results[:10])
            ]
        }
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹Rerankeræ ¼å¼éªŒè¯æµ‹è¯•\n")
    
    try:
        # 1. åŠ è½½æ¨¡å‹
        retriever, reranker = load_models()
        
        # 2. åŸºç¡€æ£€ç´¢
        query = CONFIG['test_query']
        base_results = test_base_retrieval(
            retriever,
            query,
            top_k=CONFIG['recall_k']
        )
        
        if not base_results:
            logger.error("âŒ åŸºç¡€æ£€ç´¢å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return
        
        base_time = 0.025  # å‡è®¾å€¼ï¼Œå®é™…åœ¨test_base_retrievalä¸­æµ‹é‡
        
        # 3. Rerankeræµ‹è¯•
        reranked_results, rerank_time = test_reranker(
            reranker,
            query,
            base_results,
            top_k=CONFIG['top_k']
        )
        
        # 4. å¯¹æ¯”åˆ†æ
        compare_results(
            base_results,
            reranked_results,
            top_k=CONFIG['top_k']
        )
        
        # 5. ä¿å­˜ç»“æœ
        save_results(
            query,
            base_results,
            reranked_results,
            base_time,
            rerank_time
        )
        
        # 6. æ€»ç»“
        logger.info("\n" + "=" * 80)
        logger.info("âœ… æµ‹è¯•å®Œæˆ!")
        logger.info("=" * 80)
        logger.info(f"ğŸ“Š æ€§èƒ½å¯¹æ¯”:")
        logger.info(f"   BaseRetriever: ~25ms")
        logger.info(f"   Reranker: {rerank_time*1000:.1f}ms (æ…¢ {rerank_time/0.025:.0f} å€)")
        logger.info(f"\nğŸ“ è¯¦ç»†ç»“æœ: tests/results/reranker_debug/comparison.json")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()