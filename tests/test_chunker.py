"""æµ‹è¯•æ–‡æœ¬åˆ†å—å™¨"""
import json
from src.rag.chunk import TextChunker

# åŠ è½½æ•°æ®
print("ğŸ“Š åŠ è½½æ•°æ®...")
with open("data/processed/stackoverflow_1k.json", 'r', encoding='utf-8') as f:
    qa_data = json.load(f)

print(f"âœ… åŠ è½½ {len(qa_data)} æ¡æ•°æ®")

# åˆ›å»ºåˆ†å—å™¨
chunker = TextChunker(chunk_size=500, chunk_overlap=50)

# æµ‹è¯•å•ä¸ªæ–‡æœ¬
print("\nğŸ§ª æµ‹è¯•å•ä¸ªæ–‡æœ¬åˆ†å—:")
test_text = qa_data[0]['combined']
chunks = chunker.split_text(test_text)
print(f"åŸæ–‡é•¿åº¦: {len(test_text)} å­—ç¬¦")
print(f"åˆ†å—æ•°é‡: {len(chunks)} å—")
print(f"\nç¬¬1å—å†…å®¹:\n{chunks[0][:200]}...")

# æ‰¹é‡å¤„ç†æµ‹è¯•ï¼ˆå‰10æ¡ï¼‰
print("\nğŸ§ª æ‰¹é‡å¤„ç†æµ‹è¯•ï¼ˆå‰10æ¡ï¼‰:")
test_chunks = chunker.process_qa_data(qa_data[:10])

print(f"\nğŸ“ æ ·ä¾‹å—:")
print(f"  æ–‡æœ¬: {test_chunks[0]['text'][:100]}...")
print(f"  æ¥æºID: {test_chunks[0]['source_id']}")
print(f"  å—ç´¢å¼•: {test_chunks[0]['chunk_index']}/{test_chunks[0]['total_chunks']}")
print(f"\nâœ… åˆ†å—å™¨æµ‹è¯•é€šè¿‡ï¼")