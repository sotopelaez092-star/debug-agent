# experiments/retriever/evaluate_all.py
"""æ‰¹é‡è¯„ä¼°Retrieverç­–ç•¥"""
import sys
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

import json
import logging
from typing import Dict, List, Any
import chromadb

from src.rag.evaluator import ChunkingEvaluator  # å¤ç”¨ç°æœ‰çš„è¯„ä¼°å™¨
from src.rag.retriever import BaseRetriever
from src.rag.reranker_retriever import RerankerRetriever
from src.rag.hyde_retriever import HyDERetriever
from src.rag.embedder import Embedder


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å®šä¹‰è¦å¯¹æ¯”çš„Retrievers
RETRIEVERS = {
    'R1': {
        'name': 'BaseRetriever',
        'type': 'base',
        'description': 'çº¯å‘é‡æ£€ç´¢'
    },
    'R2': {
        'name': 'RerankerRetriever', 
        'type': 'reranker',
        'reranker_model': 'BAAI/bge-reranker-base',
        'description': 'å‘é‡æ£€ç´¢ + Rerankeré‡æ’åº'
    },
    'R3': {
        'name': 'HyDERetriever',
        'type': 'hyde',
        'description': 'LLMç”Ÿæˆå‡è®¾æ–‡æ¡£ + å‘é‡æ£€ç´¢'
    }
}

# æ•°æ®è·¯å¾„
DATA_DIR = Path(__file__).parent.parent.parent / 'data'
QUERIES_PATH = DATA_DIR / 'test_cases' / 'test_queries_realistic.json'
GT_PATH = DATA_DIR / 'evaluation' / 'llm_annotated_gt.json'

# âœ… å…³é”®ï¼šä½¿ç”¨åŒä¸€ä¸ªvectorstoreï¼ˆS1-Semanticï¼‰
VECTORSTORE_PATH = DATA_DIR / 'vectorstore' / 'chroma_s1'

# Embeddingæ¨¡å‹ï¼ˆå¿…é¡»å’Œæ„å»ºå‘é‡åº“æ—¶ä¸€è‡´ï¼‰
EMBEDDING_MODEL = "BAAI/bge-small-en-v1.5"

def load_queries() -> List[Dict[str, str]]:
    """
    åŠ è½½æµ‹è¯•queries
    
    Returns:
        queriesåˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{'id': 'test-001', 'text': 'query text'}, ...]
    """
    if not QUERIES_PATH.exists():
        logger.error(f"æŸ¥è¯¢æ–‡ä»¶ä¸å­˜åœ¨: {QUERIES_PATH}")
        raise FileNotFoundError(f"æŸ¥è¯¢æ–‡ä»¶ä¸å­˜åœ¨: {QUERIES_PATH}")
    
    try:
        with open(QUERIES_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            raw_queries = data.get('queries', [])
            
            # âœ… æ ¼å¼è½¬æ¢ï¼šquery_id -> id, query -> text
            queries = []
            for q in raw_queries:
                queries.append({
                    'id': q['query_id'],
                    'text': q['query']
                })
            
            logger.info(f"æˆåŠŸåŠ è½½ {len(queries)} ä¸ªæŸ¥è¯¢")
            return queries
            
    except json.JSONDecodeError:
        logger.error(f"æŸ¥è¯¢æ–‡ä»¶ {QUERIES_PATH} æ ¼å¼é”™è¯¯")
        raise ValueError(f"æŸ¥è¯¢æ–‡ä»¶ {QUERIES_PATH} æ ¼å¼é”™è¯¯")


def load_ground_truth() -> Dict[str, List[str]]:
    """
    åŠ è½½ground truth
    
    Returns:
        ground truthå­—å…¸ï¼Œæ ¼å¼ï¼š{'test-001': ['doc-1', 'doc-2'], ...}
    """
    if not GT_PATH.exists():
        logger.error(f"ground truth æ–‡ä»¶ä¸å­˜åœ¨: {GT_PATH}")
        raise FileNotFoundError(f"ground truth æ–‡ä»¶ä¸å­˜åœ¨: {GT_PATH}")
    
    try:
        with open(GT_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            annotations = data.get('annotations', [])
            
            # è½¬æ¢æ ¼å¼
            ground_truth = {}
            for anno in annotations:
                query_id = anno['query_id']
                relevant_docs = anno.get('relevant_docs', [])
                ground_truth[query_id] = relevant_docs
            
            logger.info(f"æˆåŠŸåŠ è½½ {len(ground_truth)} ä¸ªground truth")
            return ground_truth
            
    except json.JSONDecodeError:
        logger.error(f"ground truth æ–‡ä»¶ {GT_PATH} æ ¼å¼é”™è¯¯")
        raise ValueError(f"ground truth æ–‡ä»¶ {GT_PATH} æ ¼å¼é”™è¯¯")

def evaluate_retriever(
    retriever_id: str,
    config: Dict[str, str],
    queries: List[Dict[str, str]],
    ground_truth: Dict[str, List[str]]
) -> Dict[str, Any]:
    """
    è¯„ä¼°å•ä¸ªretriever
    
    Args:
        retriever_id: Retriever IDï¼ˆå¦‚ 'R1'ï¼‰
        config: Retrieveré…ç½®
        queries: æµ‹è¯•queries
        ground_truth: ground truth
        
    Returns:
        è¯„ä¼°ç»“æœå­—å…¸
    """
    retriever_name = config['name']
    retriever_type = config['type']
    
    logger.info(f"\n{'='*60}")
    logger.info(f"è¯„ä¼°Retriever: {retriever_id} - {retriever_name}")
    logger.info(f"ç±»å‹: {retriever_type}")
    logger.info(f"{'='*60}")
    
    try:
        # 1. åŠ è½½å‘é‡åº“ï¼ˆæ‰€æœ‰retrieverç”¨åŒä¸€ä¸ªï¼‰
        if not VECTORSTORE_PATH.exists():
            raise FileNotFoundError(f"å‘é‡åº“ä¸å­˜åœ¨: {VECTORSTORE_PATH}")
        
        logger.info(f"åŠ è½½å‘é‡åº“: {VECTORSTORE_PATH}")
        client = chromadb.PersistentClient(path=str(VECTORSTORE_PATH))
        collection = client.get_collection(name="stackoverflow_kb")
        doc_count = collection.count()
        logger.info(f"CollectionåŒ…å« {doc_count} ä¸ªæ–‡æ¡£")
        
        # 2. åˆ›å»ºEmbedderï¼ˆæ‰€æœ‰retrieverç”¨åŒä¸€ä¸ªï¼‰
        embedder = Embedder(model_name=EMBEDDING_MODEL)
        logger.info("Embedderå·²åˆ›å»º")
        
        # 3. ğŸ”‘ å…³é”®ï¼šæ ¹æ®typeåˆå§‹åŒ–ä¸åŒçš„retriever
        if retriever_type == 'base':
            retriever = BaseRetriever(
                collection=collection,
                embedding_function=embedder,  # âœ… ä¿®æ­£å‚æ•°å
                min_similarity=0.5,
                recall_factor=4
            )
            logger.info("BaseRetrieverå·²åˆå§‹åŒ–")
            
        elif retriever_type == 'reranker':
            retriever = RerankerRetriever(
                collection=collection,
                embedding_function=embedder,  # âœ… ä¿®æ­£å‚æ•°å
                reranker_model_name=config['reranker_model'],  # âœ… ä¿®æ­£å‚æ•°å
                min_similarity=0.5,
                recall_factor=4
            )
            logger.info("RerankerRetrieverå·²åˆå§‹åŒ–")
        
        elif retriever_type == 'hyde':  # âœ… æ·»åŠ è¿™ä¸ªåˆ†æ”¯
            # HyDEéœ€è¦å…ˆåˆ›å»ºBaseRetriever
            base_retriever = BaseRetriever(
                collection=collection,
                embedding_function=embedder,
                min_similarity=0.5,
                recall_factor=4
            )
            # ç„¶ååˆ›å»ºHyDERetriever
            retriever = HyDERetriever(
                base_retriever=base_retriever,
                llm=None,  # ä½¿ç”¨é»˜è®¤LLMï¼ˆDeepSeekï¼‰
                enable_cache=False  # ä¸å¯ç”¨ç¼“å­˜ï¼ˆç¡®ä¿æ¯æ¬¡éƒ½é‡æ–°ç”Ÿæˆï¼‰
            )
            logger.info("HyDERetrieverå·²åˆå§‹åŒ–")
            
        else:
            raise ValueError(f"æœªçŸ¥çš„retrieverç±»å‹: {retriever_type}")
        
        # 4. åˆ›å»ºè¯„ä¼°å™¨
        evaluator = ChunkingEvaluator(retriever=retriever)
        logger.info("è¯„ä¼°å™¨å·²åˆ›å»º")
        
        # 5. æ‰§è¡Œè¯„ä¼°
        logger.info("å¼€å§‹è¯„ä¼°...")
        results = evaluator.evaluate(
            queries=queries,
            ground_truth=ground_truth,
            k_values=[1, 3, 5, 10]
        )
        
        # 6. æ·»åŠ retrieverä¿¡æ¯åˆ°ç»“æœ
        results['retriever_id'] = retriever_id
        results['retriever_name'] = retriever_name
        results['retriever_type'] = retriever_type
        results['description'] = config['description']
        results['doc_count'] = doc_count
        
        # 7. æ‰“å°ç»“æœæ‘˜è¦
        logger.info(f"\n{'='*60}")
        logger.info(f"Retriever {retriever_id} è¯„ä¼°å®Œæˆï¼")
        logger.info(f"  Recall@1:  {results['recall'].get(1, 0):.3f}")
        logger.info(f"  Recall@3:  {results['recall'].get(3, 0):.3f}")
        logger.info(f"  Recall@5:  {results['recall'].get(5, 0):.3f}")
        logger.info(f"  Recall@10: {results['recall'].get(10, 0):.3f}")
        logger.info(f"  MRR:       {results['mrr']:.3f}")
        logger.info(f"  å¹³å‡æ—¶é—´:   {results['avg_retrieval_time']:.3f}s")
        logger.info(f"  å¤±è´¥ç‡:     {results['failure_rate']:.2%}")
        logger.info(f"{'='*60}\n")
        
        return results
        
    except Exception as e:
        logger.error(f"è¯„ä¼°Retriever {retriever_id} å¤±è´¥: {e}", exc_info=True)
        raise


def print_comparison_table(all_results: Dict[str, Dict]):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "=" * 100)
    print("ğŸ“Š Retrieverç­–ç•¥å¯¹æ¯”")
    print("=" * 100)
    
    # è¡¨å¤´
    header = f"{'ID':<6} {'åç§°':<20} {'æè¿°':<25} {'R@1':<8} {'R@3':<8} {'R@5':<8} {'R@10':<8} {'MRR':<8} {'é€Ÿåº¦(ms)':<10}"
    print(header)
    print("-" * 100)
    
    # æ¯ä¸ªretrieverçš„ç»“æœ
    for retriever_id in sorted(all_results.keys()):
        results = all_results[retriever_id]
        
        row = (
            f"{retriever_id:<6} "
            f"{results['retriever_name']:<20} "
            f"{results['description']:<25} "
            f"{results['recall'].get(1, 0):.3f}    "
            f"{results['recall'].get(3, 0):.3f}    "
            f"{results['recall'].get(5, 0):.3f}    "
            f"{results['recall'].get(10, 0):.3f}    "
            f"{results['mrr']:.3f}    "
            f"{results['avg_retrieval_time']*1000:.1f}"
        )
        print(row)
    
    print("=" * 100)
    
    # æ‰¾å‡ºæœ€ä½³retriever
    best_recall5 = max(all_results.items(), key=lambda x: x[1]['recall'].get(5, 0))
    best_mrr = max(all_results.items(), key=lambda x: x[1]['mrr'])
    best_speed = min(all_results.items(), key=lambda x: x[1]['avg_retrieval_time'])
    
    print(f"\nğŸ† æœ€ä½³Retriever:")
    print(f"  - Recall@5: {best_recall5[0]} ({best_recall5[1]['recall'].get(5, 0):.3f})")
    print(f"  - MRR:      {best_mrr[0]} ({best_mrr[1]['mrr']:.3f})")
    print(f"  - é€Ÿåº¦:      {best_speed[0]} ({best_speed[1]['avg_retrieval_time']*1000:.1f}ms)")
    print()


def save_results(all_results: Dict[str, Dict]):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    results_dir = Path(__file__).parent / 'results'
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜JSON
    json_path = results_dir / 'evaluation_results.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    logger.info(f"ç»“æœå·²ä¿å­˜: {json_path}")
    
    # ä¿å­˜CSV
    csv_path = results_dir / 'evaluation_results.csv'
    with open(csv_path, 'w', encoding='utf-8') as f:
        # CSVè¡¨å¤´
        f.write("Retriever,Name,Description,Recall@1,Recall@3,Recall@5,Recall@10,MRR,AvgTime(ms),FailureRate\n")
        
        # æ¯è¡Œæ•°æ®
        for retriever_id in sorted(all_results.keys()):
            r = all_results[retriever_id]
            f.write(
                f"{retriever_id},"
                f"{r['retriever_name']},"
                f"{r['description']},"
                f"{r['recall'].get(1, 0):.3f},"
                f"{r['recall'].get(3, 0):.3f},"
                f"{r['recall'].get(5, 0):.3f},"
                f"{r['recall'].get(10, 0):.3f},"
                f"{r['mrr']:.3f},"
                f"{r['avg_retrieval_time']*1000:.1f},"
                f"{r['failure_rate']:.2%}\n"
            )
    logger.info(f"CSVå·²ä¿å­˜: {csv_path}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. åŠ è½½æ•°æ®
        logger.info("=" * 80)
        logger.info("å¼€å§‹æ‰¹é‡è¯„ä¼°Retrieverç­–ç•¥")
        logger.info("=" * 80)
        
        queries = load_queries()
        ground_truth = load_ground_truth()
        
        logger.info(f"\nåŠ è½½å®Œæˆ:")
        logger.info(f"  - Queries: {len(queries)} ä¸ª")
        logger.info(f"  - Ground Truth: {len(ground_truth)} ä¸ª")
        logger.info(f"  - Vectorstore: {VECTORSTORE_PATH}")
        logger.info(f"  - Embedding Model: {EMBEDDING_MODEL}")
        
        # 2. è¯„ä¼°æ‰€æœ‰retriever
        all_results = {}
        
        for retriever_id, config in RETRIEVERS.items():
            try:
                results = evaluate_retriever(
                    retriever_id=retriever_id,
                    config=config,
                    queries=queries,
                    ground_truth=ground_truth
                )
                all_results[retriever_id] = results
            except Exception as e:
                logger.error(f"è·³è¿‡Retriever {retriever_id}: {e}")
                continue
        
        # 3. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        if all_results:
            print_comparison_table(all_results)
            save_results(all_results)
        else:
            logger.error("æ²¡æœ‰æˆåŠŸè¯„ä¼°çš„Retrieverï¼")
            return
        
        logger.info("\n" + "=" * 80)
        logger.info("æ‰¹é‡è¯„ä¼°å®Œæˆï¼")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"ä¸»å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise


if __name__ == '__main__':
    main()