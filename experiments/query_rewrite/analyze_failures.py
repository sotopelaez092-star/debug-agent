"""
å¤±è´¥æ¡ˆä¾‹åˆ†æè„šæœ¬

åˆ†æRecall@5å¤±è´¥çš„æŸ¥è¯¢æ¡ˆä¾‹ï¼Œæ‰¾å‡ºä¼˜åŒ–æ–¹å‘
"""

import json
import logging
import sys
from pathlib import Path
from typing import Dict, List, Any, Tuple
import chromadb

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.rag.retriever import BaseRetriever
from src.rag.embedder import Embedder
from src.rag.evaluator import ChunkingEvaluator
from src.rag.query_rewriter import QueryRewriter

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_queries(file_path: str) -> List[Dict[str, str]]:
    """
    åŠ è½½æµ‹è¯•æŸ¥è¯¢

    Args: 
        file_path: æŸ¥è¯¢æ–‡ä»¶è·¯å¾„

    Returns:
        æŸ¥è¯¢åˆ—è¡¨ï¼Œæ ¼å¼: [{'id': 'test-001', 'text': 'query text'}, ...]
    
    Raises:
        FileNotFoundError: å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    # è¾“å…¥éªŒè¯
    if not Path(file_path).exists():
        raise FileNotFoundError(f"Query file not found: {file_path}")

    # è¯»å–jsonæ–‡ä»¶
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æé”™è¯¯ï¼š{e}")
        raise ValueError(f"Invalid query file format: {file_path}")

    # æå–queriesæ•°æ®
    raw_queries = data.get('queries', [])
    if not raw_queries:
        raise ValueError(f"Empty queries array in file: {file_path}")

    # è½¬æ¢æ ¼å¼ï¼ˆé€‚é…å®é™…æ–‡ä»¶æ ¼å¼ï¼‰
    queries = []
    for item in raw_queries:
        # âœ… ä¿®æ”¹ï¼šé€‚é…å®é™…çš„å­—æ®µå
        if 'query_id' not in item or 'query' not in item:
            logger.warning(f"Invalid query item format: {item}")
            continue
        
        queries.append({
            'id': item['query_id'],      # âœ… query_id â†’ id
            'text': item['query']        # âœ… query â†’ text
        })

    if not queries:
        raise ValueError(f"All query items are invalid in file: {file_path}")

    logger.info(f"Loaded {len(queries)} valid queries from {file_path}")

    return queries


def load_ground_truth(file_path: str) -> Dict[str, List[str]]:
    """
    åŠ è½½Ground Truth
    
    Args:
        file_path: Ground Truthæ–‡ä»¶è·¯å¾„
        
    Returns:
        Ground Truthå­—å…¸ï¼Œæ ¼å¼: {'test-001': ['doc-1', 'doc-2'], ...}
        
    Raises:
        FileNotFoundError: å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶
        ValueError: å½“æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®æ—¶
    """
    logger.info(f"Loading ground truth file: {file_path}")

    # è¾“å…¥éªŒè¯
    if not Path(file_path).exists():
        raise FileNotFoundError(f"Ground truth file not found: {file_path}")
    
    # è¯»å–jsonæ–‡ä»¶
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        logger.error(f"JSONè§£æé”™è¯¯ï¼š{e}")
        raise ValueError(f"Invalid ground truth file format: {file_path}")
    
    # æå–annotationsæ•°ç»„
    raw_annotations = data.get('annotations', [])
    if not raw_annotations:
        raise ValueError(f"Empty annotations array in file: {file_path}")

    # è½¬æ¢æ ¼å¼
    ground_truth = {}
    for anno in raw_annotations:
        query_id = anno.get('query_id')
        relevant_docs = anno.get('relevant_docs', [])

        if not query_id:
            logger.warning(f"Skipping annotation without query_id: {anno}")
            continue
        if not relevant_docs:
            logger.warning(f"Skipping query {query_id} with empty relevant_docs")
            continue 
        ground_truth[query_id] = relevant_docs
    
    if not ground_truth:
        raise ValueError(f"No valid annotations found in file: {file_path}")
    
    logger.info(f"Loaded {len(ground_truth)} ground truth items from {file_path}")

    return ground_truth


def initialize_retriever(
    vectorstore_path: str,
    model_name: str = "BAAI/bge-small-en-v1.5"
) -> Tuple[BaseRetriever, QueryRewriter]:
    """
    åˆå§‹åŒ–æ£€ç´¢å™¨å’Œæ”¹å†™å™¨
    
    Args:
        vectorstore_path: å‘é‡åº“è·¯å¾„
        model_name: Embeddingæ¨¡å‹åç§°
        
    Returns:
        (retriever, rewriter)
        
    Raises:
        RuntimeError: åˆå§‹åŒ–å¤±è´¥
    """
    try:
        logger.info(f"Initializing retriever with vectorstore: {vectorstore_path}")
        logger.info(f"Using embedding model: {model_name}")
        
        # 1. åˆ›å»ºEmbedder
        embedder = Embedder(model_name)
        logger.info("Embedder created")
        
        # 2. è¿æ¥ChromaDB
        client = chromadb.PersistentClient(path=str(vectorstore_path))
        collection = client.get_collection(name="stackoverflow_kb")
        logger.info(f"Connected to ChromaDB collection: stackoverflow_kb")
        
        # 3. åˆ›å»ºBaseRetriever
        retriever = BaseRetriever(
            collection=collection,
            embedding_function=embedder,
            min_similarity=0.5,
            recall_factor=4
        )
        logger.info("BaseRetriever initialized with min_similarity=0.5, recall_factor=4")
        
        # 4. åˆ›å»ºQueryRewriterï¼ˆä¸éœ€è¦å‚æ•°ï¼‰
        rewriter = QueryRewriter()
        logger.info("QueryRewriter initialized")
        
        # 5. è¿”å›ä¸¤è€…
        return retriever, rewriter
        
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {e}", exc_info=True)
        raise RuntimeError(f"åˆå§‹åŒ–æ£€ç´¢å™¨å¤±è´¥: {e}")

def retrieve_and_check(
    query: Dict[str, Any],
    ground_truth: List[str],
    retriever: BaseRetriever,
    rewriter: QueryRewriter,
    top_k: int = 20
) -> Dict[str, Any]:
    """
    æ£€ç´¢å¹¶æ£€æŸ¥Recall@5
    
    Args:
        query: æŸ¥è¯¢å­—å…¸ï¼ŒåŒ…å« 'id' å’Œ 'text'
        ground_truth: æ­£ç¡®æ–‡æ¡£IDåˆ—è¡¨
        retriever: æ£€ç´¢å™¨
        rewriter: æ”¹å†™å™¨
        top_k: è¿”å›Top-Kç»“æœï¼ˆç”¨äºåˆ†æé—æ¼æ–‡æ¡£ï¼‰
        
    Returns:
        {
            'query_id': str,
            'original_query': str,
            'rewritten_query': str,
            'ground_truth': List[str],
            'ground_truth_count': int,
            'top5_results': List[Dict],
            'top20_results': List[Dict],
            'recall_at_5': float,
            'hits_count': int,
            'hit_docs': List[Dict],
            'missed_docs': List[Dict]
        }
    """
    # 1. æå–åŸå§‹æŸ¥è¯¢
    query_id = query['id']
    original_query = query['text']
    
    logger.info(f"Processing query {query_id}: {original_query[:50]}...")

    # 2. ç”¨QueryRewriteræ”¹å†™
    rewritten_query = rewriter.rewrite(original_query)
    logger.debug(f"Rewritten query: {rewritten_query[:100]}...")
    
    # 3. ç”¨BaseRetrieveræ£€ç´¢Top-K
    top_k_results = retriever.search(rewritten_query, top_k=top_k)
    logger.debug(f"Retrieved {len(top_k_results)} results")
    
    # 4. æå–base doc_idï¼ˆå»æ‰_chunkåç¼€ï¼‰
    def extract_base_doc_id(doc_id: str) -> str:
        """æå–åŸºç¡€æ–‡æ¡£IDï¼Œå»æ‰_chunk_Xåç¼€"""
        if '_chunk_' in doc_id:
            return doc_id.split('_chunk_')[0]
        return doc_id
    
    retrieved_base_ids = [extract_base_doc_id(result['id']) for result in top_k_results]
    
    # 5. æ‰¾å‡ºTop5ä¸­å‘½ä¸­çš„æ–‡æ¡£
    hit_docs = []
    for i in range(min(5, len(top_k_results))):
        base_id = retrieved_base_ids[i]
        if base_id in ground_truth:
            hit_docs.append({
                'doc_id': base_id,
                'rank': i + 1,
                'similarity': top_k_results[i]['similarity'],
                'content_preview': top_k_results[i]['content'][:100]
            })
    
    # 6. è®¡ç®—Recall@5
    hits_count = len(hit_docs)
    recall_at_5 = hits_count / len(ground_truth) if ground_truth else 0.0
    
    logger.info(f"Recall@5: {recall_at_5:.2%} ({hits_count}/{len(ground_truth)})")
    
    # 7. æ‰¾å‡ºé—æ¼çš„æ–‡æ¡£
    hit_doc_ids = {doc['doc_id'] for doc in hit_docs}
    missed_gt_docs = set(ground_truth) - hit_doc_ids
    
    # 8. æŸ¥æ‰¾é—æ¼æ–‡æ¡£åœ¨Top-Kä¸­çš„æ’å
    missed_docs = []
    for doc_id in missed_gt_docs:
        # åœ¨Top-Kä¸­æŸ¥æ‰¾
        found = False
        for i, base_id in enumerate(retrieved_base_ids):
            if base_id == doc_id:
                missed_docs.append({
                    'doc_id': doc_id,
                    'rank': i + 1,
                    'similarity': top_k_results[i]['similarity'],
                    'status': 'in_top20'
                })
                found = True
                break
        
        if not found:
            # ä¸åœ¨Top-Kä¸­
            missed_docs.append({
                'doc_id': doc_id,
                'rank': None,
                'similarity': None,
                'status': 'not_in_top20'
            })
    
    # 9. æŒ‰æ’åæ’åºé—æ¼æ–‡æ¡£ï¼ˆæœªæ£€ç´¢åˆ°çš„æ”¾æœ€åï¼‰
    missed_docs.sort(key=lambda x: x['rank'] if x['rank'] is not None else 999)
    
    # 10. è¿”å›å®Œæ•´ä¿¡æ¯
    return {
        'query_id': query_id,
        'original_query': original_query,
        'rewritten_query': rewritten_query,
        'ground_truth': ground_truth,
        'ground_truth_count': len(ground_truth),
        
        'top5_results': top_k_results[:5],
        'top20_results': top_k_results,
        
        'recall_at_5': recall_at_5,
        'hits_count': hits_count,
        'hit_docs': hit_docs,
        'missed_docs': missed_docs
    }


def analyze_failure_pattern(failure_cases: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    åˆ†æå¤±è´¥æ¡ˆä¾‹çš„æ¨¡å¼
    
    Args:
        failure_cases: å¤±è´¥æ¡ˆä¾‹åˆ—è¡¨
        
    Returns:
        åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
        - æ€»å¤±è´¥æ•°
        - å¤±è´¥æŸ¥è¯¢é•¿åº¦åˆ†å¸ƒ
        - æ”¹å†™åé•¿åº¦åˆ†å¸ƒ
        - Top1ç›¸ä¼¼åº¦åˆ†å¸ƒ
        - å¯èƒ½çš„å¤±è´¥åŸå› åˆ†ç±»
    """
    if not failure_cases:
        return {
            'total_failures': 0,
            'query_lengths': [],
            'rewritten_lengths': [],
            'top1_similarities': [],
            'low_sim_cases': [],
            'high_sim_cases': []
        }
    
    # 1. ç»Ÿè®¡å¤±è´¥æ¡ˆä¾‹ç‰¹å¾
    total_failures = len(failure_cases)

    # 2. åˆ†ææŸ¥è¯¢é•¿åº¦
    query_lengths = [len(case['original_query']) for case in failure_cases]
    rewritten_lengths = [len(case['rewritten_query']) for case in failure_cases]

    # 3. åˆ†æç›¸ä¼¼åº¦åˆ†å¸ƒ
    top1_similarities = [
        case['results'][0]['similarity'] 
        for case in failure_cases 
        if case['results']
    ]

    # 4. å°è¯•åˆ†ç±»å¤±è´¥åŸå› 
    # æ ¹æ®Top1ç›¸ä¼¼åº¦åˆ†ç±»
    low_sim_cases = [
        case for case in failure_cases 
        if case['results'] and case['results'][0]['similarity'] < 0.5
    ]
    high_sim_cases = [
        case for case in failure_cases 
        if case['results'] and case['results'][0]['similarity'] >= 0.5
    ]

    return {
        'total_failures': total_failures,
        'query_lengths': {
            'min': min(query_lengths) if query_lengths else 0,
            'max': max(query_lengths) if query_lengths else 0,
            'avg': sum(query_lengths) / len(query_lengths) if query_lengths else 0
        },
        'rewritten_lengths': {
            'min': min(rewritten_lengths) if rewritten_lengths else 0,
            'max': max(rewritten_lengths) if rewritten_lengths else 0,
            'avg': sum(rewritten_lengths) / len(rewritten_lengths) if rewritten_lengths else 0
        },
        'top1_similarities': {
            'min': min(top1_similarities) if top1_similarities else 0,
            'max': max(top1_similarities) if top1_similarities else 0,
            'avg': sum(top1_similarities) / len(top1_similarities) if top1_similarities else 0
        },
        'low_sim_count': len(low_sim_cases),
        'high_sim_count': len(high_sim_cases)
    }


def print_failure_case(case: Dict[str, Any], index: int):
    """
    æ‰“å°å•ä¸ªå¤±è´¥æ¡ˆä¾‹
    
    Args:
        case: å¤±è´¥æ¡ˆä¾‹å­—å…¸
        index: æ¡ˆä¾‹ç¼–å·
    """
    print(f"\n{'='*60}")
    print(f"å¤±è´¥æ¡ˆä¾‹ #{index}")
    print(f"{'='*60}")
    print(f"Query ID: {case['query_id']}")
    print(f"åŸå§‹æŸ¥è¯¢: {case['original_query']}")
    print(f"æ”¹å†™å: {case['rewritten_query']}")
    print(f"\nGround Truth: {case['ground_truth']}")
    print(f"\nTop5æ£€ç´¢ç»“æœ:")
    
    for i, result in enumerate(case['results'][:5], 1):
        print(f"\n  [{i}] Doc ID: {result['id']}")
        print(f"      ç›¸ä¼¼åº¦: {result['similarity']:.4f}")
        # å†…å®¹é¢„è§ˆï¼ˆæœ€å¤š100å­—ç¬¦ï¼‰
        content_preview = result.get('content', '')[:100]
        if len(result.get('content', '')) > 100:
            content_preview += "..."
        print(f"      å†…å®¹: {content_preview}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    TEST_QUERIES_PATH = "data/test_cases/test_queries_realistic.json"
    GROUND_TRUTH_PATH = "data/evaluation/llm_annotated_gt.json"
    VECTORSTORE_PATH = "data/vectorstore/chroma_s1"
    
    logger.info("="*60)
    logger.info("å¼€å§‹å¤±è´¥æ¡ˆä¾‹åˆ†æ")
    logger.info("="*60)
    
    try:
        # 1. åŠ è½½æ•°æ®
        logger.info("Step 1: åŠ è½½æµ‹è¯•æ•°æ®...")
        test_queries = load_queries(TEST_QUERIES_PATH)
        ground_truth = load_ground_truth(GROUND_TRUTH_PATH)
        
        # 2. åˆå§‹åŒ–æ£€ç´¢å™¨
        logger.info("Step 2: åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ...")
        retriever, rewriter = initialize_retriever(VECTORSTORE_PATH)
        
        # 3. å¯¹æ¯ä¸ªæŸ¥è¯¢è¿›è¡Œæ£€ç´¢å’Œæ£€æŸ¥
        logger.info("Step 3: å¼€å§‹æ£€ç´¢å’Œæ£€æŸ¥...")
        logger.info(f"Total queries to process: {len(test_queries)}")
        
        # åˆ†ç±»å®¹å™¨
        perfect_cases = []      # Recall = 1.0
        good_cases = []         # 0.8 â‰¤ Recall < 1.0
        moderate_cases = []     # 0.5 â‰¤ Recall < 0.8
        poor_cases = []         # Recall < 0.5
        skipped = 0
        
        # å¤„ç†æ¯ä¸ªæŸ¥è¯¢
        for idx, query in enumerate(test_queries, 1):
            query_id = query['id']
            
            logger.info(f"\n[{idx}/{len(test_queries)}] Processing {query_id}...")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ground truth
            if query_id not in ground_truth:
                logger.warning(f"Query {query_id} æ²¡æœ‰ground truthï¼Œè·³è¿‡")
                skipped += 1
                continue
            
            gt_docs = ground_truth[query_id]
            
            # æ£€ç´¢å’Œæ£€æŸ¥
            result = retrieve_and_check(
                query=query,
                ground_truth=gt_docs,
                retriever=retriever,
                rewriter=rewriter,
                top_k=20  # æ£€ç´¢Top20ç”¨äºåˆ†æ
            )
            
            recall = result['recall_at_5']
            
            # åˆ†ç±»
            if recall == 1.0:
                perfect_cases.append(result)
                logger.info(f"âœ… {query_id}: å®Œç¾ (Recall@5={recall:.2%})")
            elif recall >= 0.8:
                good_cases.append(result)
                logger.info(f"âœ… {query_id}: è‰¯å¥½ (Recall@5={recall:.2%})")
            elif recall >= 0.5:
                moderate_cases.append(result)
                logger.warning(f"âš ï¸  {query_id}: ä¸­ç­‰ (Recall@5={recall:.2%})")
            else:
                poor_cases.append(result)
                logger.warning(f"âŒ {query_id}: è¾ƒå·® (Recall@5={recall:.2%})")
    
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        all_cases = perfect_cases + good_cases + moderate_cases + poor_cases
        total_processed = len(all_cases)
        all_recalls = [r['recall_at_5'] for r in all_cases]
        avg_recall = sum(all_recalls) / len(all_recalls) if all_recalls else 0.0
        
        # ============ æ‰“å°ç»Ÿè®¡å’Œè¯¦ç»†ä¿¡æ¯ ============
        
        print("\n" + "="*60)
        print("åˆ†æç»“æœç»Ÿè®¡")
        print("="*60)
        print(f"æ€»æŸ¥è¯¢æ•°: {len(test_queries)}")
        print(f"å¤„ç†æŸ¥è¯¢: {total_processed}")
        print(f"è·³è¿‡æŸ¥è¯¢: {skipped}")
        
        print("\n" + "="*60)
        print("Recall@5 åˆ†å¸ƒç»Ÿè®¡")
        print("="*60)
        print(f"å®Œç¾ (Recall=1.0):           {len(perfect_cases)} ä¸ª ({len(perfect_cases)/total_processed*100:.1f}%)")
        print(f"è‰¯å¥½ (0.8â‰¤Recall<1.0):       {len(good_cases)} ä¸ª ({len(good_cases)/total_processed*100:.1f}%)")
        print(f"ä¸­ç­‰ (0.5â‰¤Recall<0.8):       {len(moderate_cases)} ä¸ª ({len(moderate_cases)/total_processed*100:.1f}%)")
        print(f"è¾ƒå·® (Recall<0.5):           {len(poor_cases)} ä¸ª ({len(poor_cases)/total_processed*100:.1f}%)")
        print(f"\nå¹³å‡Recall@5: {avg_recall:.2%}")
        
        # 2. è¯¦ç»†åˆ†æè¾ƒå·®æ¡ˆä¾‹
        if poor_cases:
            print("\n" + "="*60)
            print(f"è¾ƒå·®æ¡ˆä¾‹è¯¦æƒ… (å…± {len(poor_cases)} ä¸ª)")
            print("="*60)
            
            for i, case in enumerate(poor_cases, 1):
                print(f"\n{'='*60}")
                print(f"æ¡ˆä¾‹ #{i}: {case['query_id']}")
                print(f"{'='*60}")
                print(f"åŸå§‹æŸ¥è¯¢: {case['original_query']}")
                print(f"æ”¹å†™å: {case['rewritten_query'][:100]}...")
                print(f"Recall@5: {case['recall_at_5']:.2%} ({case['hits_count']}/{case['ground_truth_count']})")
                
                # å‘½ä¸­æƒ…å†µ
                print(f"\nâœ… Top5å‘½ä¸­ ({len(case['hit_docs'])}ä¸ª):")
                if case['hit_docs']:
                    for doc in case['hit_docs']:
                        print(f"  Rank {doc['rank']}: {doc['doc_id']} (ç›¸ä¼¼åº¦ {doc['similarity']:.4f})")
                else:
                    print("  (æ— )")
                
                # é—æ¼æƒ…å†µ
                print(f"\nâŒ é—æ¼æ–‡æ¡£ ({len(case['missed_docs'])}ä¸ª):")
                for doc in case['missed_docs']:
                    if doc['status'] == 'in_top20':
                        print(f"  Rank {doc['rank']:2d}: {doc['doc_id']} (ç›¸ä¼¼åº¦ {doc['similarity']:.4f})")
                    else:
                        print(f"  Rank >20: {doc['doc_id']} (æœªæ£€ç´¢åˆ°)")
        else:
            print("\nğŸ‰ å¤ªæ£’äº†ï¼æ²¡æœ‰è¾ƒå·®æ¡ˆä¾‹ï¼")
        
        # 3. ä¸­ç­‰æ¡ˆä¾‹ç®€è¦ç»Ÿè®¡
        if moderate_cases:
            print("\n" + "="*60)
            print(f"ä¸­ç­‰æ¡ˆä¾‹ç»Ÿè®¡ (å…± {len(moderate_cases)} ä¸ª)")
            print("="*60)
            for case in moderate_cases:
                print(f"{case['query_id']}: Recall@5={case['recall_at_5']:.2%} ({case['hits_count']}/{case['ground_truth_count']})")
        
        # 4. è‰¯å¥½æ¡ˆä¾‹ç®€è¦ç»Ÿè®¡
        if good_cases:
            print("\n" + "="*60)
            print(f"è‰¯å¥½æ¡ˆä¾‹ç»Ÿè®¡ (å…± {len(good_cases)} ä¸ª)")
            print("="*60)
            for case in good_cases:
                print(f"{case['query_id']}: Recall@5={case['recall_at_5']:.2%} ({case['hits_count']}/{case['ground_truth_count']})")
        
        # 5. å®Œç¾æ¡ˆä¾‹ç®€è¦ç»Ÿè®¡
        if perfect_cases:
            print("\n" + "="*60)
            print(f"å®Œç¾æ¡ˆä¾‹ (å…± {len(perfect_cases)} ä¸ª)")
            print("="*60)
            print(f"ä»¥ä¸‹æŸ¥è¯¢è¾¾åˆ°äº†Recall@5=100%:")
            for case in perfect_cases:
                print(f"  {case['query_id']} ({case['ground_truth_count']}ä¸ªç›¸å…³æ–‡æ¡£å…¨éƒ¨æ£€ç´¢åˆ°)")
        
        # 6. ä¿å­˜åˆ°æ–‡ä»¶
        output_dir = Path("experiments/query_rewrite/results")
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / "recall_analysis.json"
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_data = {
            'summary': {
                'total_queries': len(test_queries),
                'processed_queries': total_processed,
                'skipped': skipped,
                'avg_recall_at_5': avg_recall,
                'distribution': {
                    'perfect': len(perfect_cases),
                    'good': len(good_cases),
                    'moderate': len(moderate_cases),
                    'poor': len(poor_cases)
                }
            },
            'poor_cases': poor_cases,
            'moderate_cases': moderate_cases,
            'good_cases': good_cases,
            'perfect_cases': perfect_cases
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nâœ… åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ° {output_path}")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {e}", exc_info=True)
        raise



if __name__ == "__main__":
    main()