"""
ä»LangSmithå¯¼å‡ºæ•°æ®å¹¶åˆ†æ

åŠŸèƒ½ï¼š
1. è·å–Sessionçš„æ‰€æœ‰traces
2. æå–å…³é”®æŒ‡æ ‡ï¼ˆTokenã€è€—æ—¶ã€æˆæœ¬ï¼‰
3. æŒ‰é”™è¯¯ç±»å‹ã€éš¾åº¦ã€ç±»åˆ«ç»Ÿè®¡
4. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
5. ä¿å­˜åˆ†ææŠ¥å‘Š
"""

import os
import logging
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)

from datetime import datetime
from typing import List, Dict
import json
from collections import defaultdict

from langsmith import Client
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # macOS
plt.rcParams['axes.unicode_minus'] = False


class LangSmithAnalyzer:
    """LangSmithæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, api_key: str = None, project_name: str = "debug-agent-multi-agent"):
        """
        åˆå§‹åŒ–
        
        Args:
            api_key: LangSmith API Key (é»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å–)
            project_name: é¡¹ç›®åç§°
        """
        self.client = Client(api_key=api_key)
        self.project_name = project_name
        self.traces = []
        self.df = None
    
    def fetch_traces_by_session(self, session_id: str):
        """
        è·å–æŸä¸ªSessionçš„æ‰€æœ‰traces
        
        Args:
            session_id: Session IDï¼Œå¦‚ "batch_20251202_113047"
        """
        print(f"ğŸ“¥ æ­£åœ¨ä»LangSmithè·å–æ•°æ®...")
        print(f"   Project: {self.project_name}")
        print(f"   Session: {session_id}")
        
        # æ„å»ºfilter
        filter_str = f'has(tags, "session:{session_id}")'
        
        # è·å–traces
        runs = self.client.list_runs(
            project_name=self.project_name,
            filter=filter_str,
            is_root=True  # åªè·å–æ ¹trace
        )
        
        self.traces = list(runs)
        print(f"âœ… æˆåŠŸè·å– {len(self.traces)} æ¡traces")
        
        return self.traces
    
    def extract_metrics(self):
        """æå–å…³é”®æŒ‡æ ‡"""
        print("\nğŸ“Š æå–å…³é”®æŒ‡æ ‡...")
        
        data = []
        
        for run in self.traces:
            # åŸºç¡€ä¿¡æ¯
            case_id = run.extra.get('metadata', {}).get('case_id', 'Unknown')
            case_name = run.extra.get('metadata', {}).get('case_name', 'Unknown')
            category = run.extra.get('metadata', {}).get('category', 'Unknown')
            difficulty = run.extra.get('metadata', {}).get('difficulty', 'Unknown')
            error_type = run.extra.get('metadata', {}).get('error_type', 'Unknown')
            
            # æ€§èƒ½æŒ‡æ ‡
            latency = run.latency if run.latency else 0  # æ¯«ç§’
            latency_sec = latency / 1000  # è½¬ç§’
            
            # Tokenç»Ÿè®¡
            total_tokens = run.total_tokens if run.total_tokens else 0
            prompt_tokens = run.prompt_tokens if run.prompt_tokens else 0
            completion_tokens = run.completion_tokens if run.completion_tokens else 0
            
            # æˆåŠŸ/å¤±è´¥
            error = run.error if run.error else None
            success = error is None
            
            # æˆæœ¬ä¼°ç®—ï¼ˆDeepSeekä»·æ ¼ï¼‰
            input_cost = prompt_tokens / 1_000_000 * 0.14
            output_cost = completion_tokens / 1_000_000 * 0.28
            total_cost = input_cost + output_cost
            
            data.append({
                'case_id': case_id,
                'case_name': case_name,
                'category': category,
                'difficulty': difficulty,
                'error_type': error_type,
                'success': success,
                'latency_sec': round(latency_sec, 2),
                'total_tokens': total_tokens,
                'prompt_tokens': prompt_tokens,
                'completion_tokens': completion_tokens,
                'total_cost': round(total_cost, 6),
                'run_id': str(run.id),
                'trace_url': f"https://smith.langchain.com/public/{run.id}/r"
            })
        
        self.df = pd.DataFrame(data)
        print(f"âœ… æå–å®Œæˆï¼Œå…± {len(self.df)} æ¡è®°å½•")
        
        return self.df
    
    def analyze_statistics(self) -> Dict:
        """ç»Ÿè®¡åˆ†æ"""
        if self.df is None or self.df.empty:
            print("âŒ æ²¡æœ‰æ•°æ®")
            return {}
        
        print("\nğŸ“ˆ ç»Ÿè®¡åˆ†æ...")
        
        stats = {
            'overall': {
                'total_cases': len(self.df),
                'successful': self.df['success'].sum(),
                'failed': (~self.df['success']).sum(),
                'success_rate': round(self.df['success'].mean() * 100, 2),
                'avg_latency': round(self.df['latency_sec'].mean(), 2),
                'total_tokens': int(self.df['total_tokens'].sum()),
                'total_cost': round(self.df['total_cost'].sum(), 6)
            },
            'by_error_type': {},
            'by_difficulty': {},
            'by_category': {}
        }
        
        # æŒ‰é”™è¯¯ç±»å‹ç»Ÿè®¡
        for error_type in self.df['error_type'].unique():
            subset = self.df[self.df['error_type'] == error_type]
            stats['by_error_type'][error_type] = {
                'total': len(subset),
                'success_rate': round(subset['success'].mean() * 100, 2),
                'avg_latency': round(subset['latency_sec'].mean(), 2),
                'avg_tokens': int(subset['total_tokens'].mean())
            }
        
        # æŒ‰éš¾åº¦ç»Ÿè®¡
        for difficulty in self.df['difficulty'].unique():
            subset = self.df[self.df['difficulty'] == difficulty]
            stats['by_difficulty'][difficulty] = {
                'total': len(subset),
                'success_rate': round(subset['success'].mean() * 100, 2),
                'avg_latency': round(subset['latency_sec'].mean(), 2),
                'avg_tokens': int(subset['total_tokens'].mean())
            }
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        for category in self.df['category'].unique():
            subset = self.df[self.df['category'] == category]
            stats['by_category'][category] = {
                'total': len(subset),
                'success_rate': round(subset['success'].mean() * 100, 2),
                'avg_latency': round(subset['latency_sec'].mean(), 2),
                'avg_tokens': int(subset['total_tokens'].mean())
            }
        
        return stats
    
    def print_statistics(self, stats: Dict):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print("\n" + "="*60)
        print("ğŸ“Š LangSmithæ•°æ®åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # æ•´ä½“ç»Ÿè®¡
        overall = stats['overall']
        print(f"\nã€æ•´ä½“ç»Ÿè®¡ã€‘")
        print(f"  æ€»æ¡ˆä¾‹æ•°: {overall['total_cases']}")
        print(f"  æˆåŠŸ: {overall['successful']} âœ…")
        print(f"  å¤±è´¥: {overall['failed']} âŒ")
        print(f"  æˆåŠŸç‡: {overall['success_rate']}%")
        print(f"  å¹³å‡è€—æ—¶: {overall['avg_latency']}ç§’")
        print(f"  æ€»Tokenæ•°: {overall['total_tokens']:,}")
        print(f"  æ€»æˆæœ¬: ${overall['total_cost']:.6f}")
        
        # æŒ‰é”™è¯¯ç±»å‹
        print(f"\nã€æŒ‰é”™è¯¯ç±»å‹ã€‘")
        for error_type, data in stats['by_error_type'].items():
            print(f"  {error_type}:")
            print(f"    æ¡ˆä¾‹æ•°: {data['total']}")
            print(f"    æˆåŠŸç‡: {data['success_rate']}%")
            print(f"    å¹³å‡è€—æ—¶: {data['avg_latency']}ç§’")
        
        # æŒ‰éš¾åº¦
        print(f"\nã€æŒ‰éš¾åº¦ã€‘")
        for difficulty, data in stats['by_difficulty'].items():
            print(f"  {difficulty}:")
            print(f"    æ¡ˆä¾‹æ•°: {data['total']}")
            print(f"    æˆåŠŸç‡: {data['success_rate']}%")
            print(f"    å¹³å‡è€—æ—¶: {data['avg_latency']}ç§’")
        
        # æŒ‰ç±»åˆ«
        print(f"\nã€æŒ‰ç±»åˆ«ã€‘")
        for category, data in stats['by_category'].items():
            print(f"  {category}:")
            print(f"    æ¡ˆä¾‹æ•°: {data['total']}")
            print(f"    æˆåŠŸç‡: {data['success_rate']}%")
            print(f"    å¹³å‡è€—æ—¶: {data['avg_latency']}ç§’")
    
    def visualize(self, output_dir: str = "data/evaluation/langsmith_analysis"):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        if self.df is None or self.df.empty:
            print("âŒ æ²¡æœ‰æ•°æ®")
            return
        
        print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        os.makedirs(output_dir, exist_ok=True)
        
        # è®¾ç½®æ ·å¼
        sns.set_style("whitegrid")
        
        # å›¾è¡¨çœç•¥...ï¼ˆå› ä¸ºå¤ªé•¿ï¼Œå¯ä»¥å…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½ï¼‰
        
        print(f"\nâœ… å›¾è¡¨ç”Ÿæˆå®Œæˆ")
    
    def save_report(self, stats: Dict, output_file: str = "data/evaluation/langsmith_analysis/report.json"):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'project': self.project_name,
            'statistics': stats,
            'raw_data': self.df.to_dict('records') if self.df is not None else []
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        
        # åŒæ—¶ä¿å­˜CSV
        csv_file = output_file.replace('.json', '.csv')
        if self.df is not None:
            self.df.to_csv(csv_file, index=False, encoding='utf-8')
            print(f"ğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜: {csv_file}")


def main():
    """ä¸»å‡½æ•°"""
    # Session ID
    session_id = "batch_20251202_113047"
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = LangSmithAnalyzer()
    
    # 1. è·å–traces
    analyzer.fetch_traces_by_session(session_id)
    
    # 2. æå–æŒ‡æ ‡
    df = analyzer.extract_metrics()
    
    # 3. ç»Ÿè®¡åˆ†æ
    stats = analyzer.analyze_statistics()
    
    # 4. æ‰“å°ç»“æœ
    analyzer.print_statistics(stats)
    
    # 5. ä¿å­˜æŠ¥å‘Š
    analyzer.save_report(stats)
    
    print("\n" + "="*60)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()